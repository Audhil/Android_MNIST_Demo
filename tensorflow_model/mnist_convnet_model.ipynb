{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"tensorflow - 1.3.0\n",
    "python - 3.6.3\"\"\"\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "MODEL_NAME = 'mnist_for_android_convnet'\n",
    "NUM_STEPS = 3000\n",
    "BATCH_SIZE = 16\n",
    "os_path = os.path\n",
    "\n",
    "\n",
    "# model input \n",
    "def model_input(input_node_name, keep_prob_node_name):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 28 * 28], name=input_node_name)\n",
    "    keep_prob = tf.placeholder(tf.float32, name=keep_prob_node_name)\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "    return x, keep_prob, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "def build_model(x, keep_prob, y_, output_node_name):\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    # 28*28*1\n",
    "\n",
    "    conv1 = tf.layers.conv2d(x_image, 64, 3, 1, 'same', activation=tf.nn.relu)\n",
    "    # 28*28*64\n",
    "\n",
    "    pool1 = tf.layers.max_pooling2d(conv1, 2, 2, 'same')\n",
    "    # 14*14*64\n",
    "\n",
    "    conv2 = tf.layers.conv2d(pool1, 128, 3, 1, 'same', activation=tf.nn.relu)\n",
    "    # 14*14*128\n",
    "\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, 2, 2, 'same')\n",
    "    # 7*7*128\n",
    "\n",
    "    conv3 = tf.layers.conv2d(pool2, 256, 3, 1, 'same', activation=tf.nn.relu)\n",
    "    # 7*7*256\n",
    "\n",
    "    pool3 = tf.layers.max_pooling2d(conv3, 2, 2, 'same')\n",
    "    # 4*4*256\n",
    "\n",
    "    flatten = tf.reshape(pool3, [-1, 4 * 4 * 256])\n",
    "    fc = tf.layers.dense(flatten, 1024, activation=tf.nn.relu)\n",
    "    dropout = tf.nn.dropout(fc, keep_prob)\n",
    "    logits = tf.layers.dense(dropout, 10)\n",
    "    outputs = tf.nn.softmax(logits, name=output_node_name)\n",
    "\n",
    "    # loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits))\n",
    "\n",
    "    # train step\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "    # accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "    return train_step, loss, accuracy, merged_summary_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train(x, keep_prob, y_, train_step, loss, accuracy, merged_summary_op, saver):\n",
    "    print('training started...')\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        tf.train.write_graph(sess.graph_def, 'out', MODEL_NAME + '.pbtxt', True)\n",
    "\n",
    "        # op to write logs to Tensorboard\n",
    "        summary_writer = tf.summary.FileWriter('logs/', graph=tf.get_default_graph())\n",
    "\n",
    "        for step in range(NUM_STEPS):\n",
    "            batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "            if step % 100 == 0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "                print('step %d, training accuracy %f' % (step, train_accuracy))\n",
    "            _, summary = sess.run([train_step, merged_summary_op], feed_dict={x: batch[0], y_: batch[1], keep_prob: .5})\n",
    "            summary_writer.add_summary(summary, step)\n",
    "        saver.save(sess, 'out/' + MODEL_NAME + '.chkp')\n",
    "        test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "        print('test accuracy %g' % test_accuracy)\n",
    "\n",
    "    print('training finished...!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model\n",
    "def export_model(input_node_names, output_node_name):\n",
    "    freeze_graph.freeze_graph('out/' + MODEL_NAME + '.pbtxt', None, False,\n",
    "                              'out/' + MODEL_NAME + '.chkp', output_node_name, \"save/restore_all\",\n",
    "                              \"save/Const:0\", 'out/frozen_' + MODEL_NAME + '.pb', True, \"\")\n",
    "\n",
    "    input_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.Open('out/frozen_' + MODEL_NAME + '.pb', \"rb\") as f:\n",
    "        input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "        input_graph_def, input_node_names, [output_node_name],\n",
    "        tf.float32.as_datatype_enum)\n",
    "\n",
    "    with tf.gfile.FastGFile('out/opt_' + MODEL_NAME + '.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "    print(\"graph saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not os_path.exists('out'):\n",
    "        os.mkdir('out')\n",
    "\n",
    "    input_node_name = 'input'\n",
    "    keep_prob_node_name = 'keep_prob'\n",
    "    output_node_name = 'output'\n",
    "\n",
    "    x, keep_prob, y_ = model_input(input_node_name, keep_prob_node_name)\n",
    "\n",
    "    train_step, loss, accuracy, merged_summary_op = build_model(x, keep_prob, y_, output_node_name)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    train(x, keep_prob, y_, train_step, loss, accuracy, merged_summary_op, saver)\n",
    "\n",
    "    export_model([input_node_name, keep_prob_node_name], output_node_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started...\nExtracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.125000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100, training accuracy 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200, training accuracy 0.750000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 300, training accuracy 0.812500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 400, training accuracy 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 500, training accuracy 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 600, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 700, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 800, training accuracy 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 900, training accuracy 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1100, training accuracy 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1200, training accuracy 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1300, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1400, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1500, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1600, training accuracy 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1800, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1900, training accuracy 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2100, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2200, training accuracy 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2300, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2400, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2500, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2600, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2700, training accuracy 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2800, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2900, training accuracy 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9843\ntraining finished...!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from out/mnist_for_android_convnet.chkp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 10 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 10 variables to const ops.\n55 ops in the final graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph saved!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
